{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\91637\\AppData\\Local\\Temp\\ipykernel_3300\\1968689114.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\91637\\AppData\\Local\\Temp\\ipykernel_3300\\1968689114.py:55: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "Epoch 1, Loss: 0.1394, Train Accuracy: 95.74, Test Accuracy: 95.56\n",
      "Epoch 2, Loss: 0.0835, Train Accuracy: 97.38, Test Accuracy: 96.74\n",
      "Epoch 3, Loss: 0.0788, Train Accuracy: 97.42, Test Accuracy: 96.50\n",
      "Epoch 4, Loss: 0.0894, Train Accuracy: 97.03, Test Accuracy: 96.02\n",
      "Epoch 5, Loss: 0.0746, Train Accuracy: 97.52, Test Accuracy: 95.85\n",
      "Epoch 6, Loss: 0.0618, Train Accuracy: 97.93, Test Accuracy: 96.47\n",
      "Epoch 7, Loss: 0.0499, Train Accuracy: 98.35, Test Accuracy: 96.78\n",
      "Epoch 8, Loss: 0.0564, Train Accuracy: 98.14, Test Accuracy: 96.68\n",
      "Epoch 9, Loss: 0.0329, Train Accuracy: 98.90, Test Accuracy: 97.18\n",
      "Epoch 10, Loss: 0.0362, Train Accuracy: 98.83, Test Accuracy: 97.10\n",
      "Epoch 11, Loss: 0.0308, Train Accuracy: 99.02, Test Accuracy: 97.41\n",
      "Epoch 12, Loss: 0.0309, Train Accuracy: 98.97, Test Accuracy: 97.18\n",
      "Epoch 13, Loss: 0.0357, Train Accuracy: 98.85, Test Accuracy: 97.09\n",
      "Epoch 14, Loss: 0.0312, Train Accuracy: 98.97, Test Accuracy: 97.43\n",
      "Epoch 15, Loss: 0.0436, Train Accuracy: 98.65, Test Accuracy: 96.77\n",
      "Epoch 16, Loss: 0.0270, Train Accuracy: 99.11, Test Accuracy: 97.16\n",
      "Epoch 17, Loss: 0.0203, Train Accuracy: 99.30, Test Accuracy: 97.56\n",
      "Epoch 18, Loss: 0.0294, Train Accuracy: 99.04, Test Accuracy: 97.20\n",
      "Epoch 19, Loss: 0.0304, Train Accuracy: 99.01, Test Accuracy: 97.36\n",
      "Epoch 20, Loss: 0.0270, Train Accuracy: 99.06, Test Accuracy: 97.23\n",
      "Final Train Accuracy: 99.06\n",
      "Final Test Accuracy: 97.23\n",
      "Training Complete!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "\n",
    "disable_eager_execution()  # Disable eager execution to use TensorFlow's graph execution\n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train.reshape(-1, 784) / 255.0, x_test.reshape(-1, 784) / 255.0\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = np.eye(10)[y_train]\n",
    "y_test = np.eye(10)[y_test]\n",
    "\n",
    "# Define model hyperparameters\n",
    "input_size = 784\n",
    "hidden1_size = 128\n",
    "hidden2_size = 64\n",
    "output_size = 10\n",
    "learning_rate = 0.01\n",
    "batch_size = 100\n",
    "epochs = 20\n",
    "\n",
    "# Define placeholders for input and output\n",
    "X = tf.compat.v1.placeholder(tf.float32, [None, input_size])\n",
    "y = tf.compat.v1.placeholder(tf.float32, [None, output_size])\n",
    "\n",
    "# Initialize weights and biases\n",
    "weights = {\n",
    "    'w1': tf.Variable(tf.random.truncated_normal([input_size, hidden1_size], stddev=0.1)),\n",
    "    'w2': tf.Variable(tf.random.truncated_normal([hidden1_size, hidden2_size], stddev=0.1)),\n",
    "    'w3': tf.Variable(tf.random.truncated_normal([hidden2_size, output_size], stddev=0.1))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.zeros([hidden1_size])),\n",
    "    'b2': tf.Variable(tf.zeros([hidden2_size])),\n",
    "    'b3': tf.Variable(tf.zeros([output_size]))\n",
    "}\n",
    "\n",
    "# Define feed-forward neural network\n",
    "def neural_network(X):\n",
    "    layer1 = tf.nn.sigmoid(tf.matmul(X, weights['w1']) + biases['b1'])\n",
    "    layer2 = tf.nn.sigmoid(tf.matmul(layer1, weights['w2']) + biases['b2'])\n",
    "    output_layer = tf.matmul(layer2, weights['w3']) + biases['b3']\n",
    "    return output_layer\n",
    "\n",
    "# Compute logits\n",
    "logits = neural_network(X)\n",
    "\n",
    "# Define loss function (cross-entropy)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits))\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "# Define accuracy metric\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Run session\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(tf.compat.v1.global_variables_initializer())\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, len(x_train), batch_size):\n",
    "            batch_x, batch_y = x_train[i:i+batch_size], y_train[i:i+batch_size]\n",
    "            sess.run(optimizer, feed_dict={X: batch_x, y: batch_y})\n",
    "        \n",
    "        # Calculate and display loss and accuracy at each epoch\n",
    "        train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: x_train, y: y_train})\n",
    "        test_acc = sess.run(accuracy, feed_dict={X: x_test, y: y_test})\n",
    "        print(f\"Epoch {epoch+1}, Loss: {train_loss:.4f}, Train Accuracy: {train_acc*100:.2f}, Test Accuracy: {test_acc*100:.2f}\")\n",
    "    \n",
    "    # Compute final train and test accuracy\n",
    "    final_train_acc = sess.run(accuracy, feed_dict={X: x_train, y: y_train})\n",
    "    final_test_acc = sess.run(accuracy, feed_dict={X: x_test, y: y_test})\n",
    "    print(f\"Final Train Accuracy: {final_train_acc*100:.2f}\")\n",
    "    print(f\"Final Test Accuracy: {final_test_acc*100:.2f}\")\n",
    "    \n",
    "    print(\"Training Complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
